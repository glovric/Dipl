{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # type: ignore\n",
    "import pandas as pd # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import yfinance as yf # type: ignore\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "data = yf.download('AAPL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-12-12</th>\n",
       "      <td>0.098834</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>469033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-15</th>\n",
       "      <td>0.093678</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.122210</td>\n",
       "      <td>175884800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-16</th>\n",
       "      <td>0.086802</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>105728000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-17</th>\n",
       "      <td>0.088951</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.116071</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>86441600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-18</th>\n",
       "      <td>0.091530</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.119420</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>73449600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price      Adj Close     Close      High       Low      Open     Volume\n",
       "Ticker          AAPL      AAPL      AAPL      AAPL      AAPL       AAPL\n",
       "Date                                                                   \n",
       "1980-12-12  0.098834  0.128348  0.128906  0.128348  0.128348  469033600\n",
       "1980-12-15  0.093678  0.121652  0.122210  0.121652  0.122210  175884800\n",
       "1980-12-16  0.086802  0.112723  0.113281  0.112723  0.113281  105728000\n",
       "1980-12-17  0.088951  0.115513  0.116071  0.115513  0.115513   86441600\n",
       "1980-12-18  0.091530  0.118862  0.119420  0.118862  0.118862   73449600"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11091, 6)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.to_numpy()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence(data: np.ndarray, seq_len: int = 8, target_sequence: bool = False) -> tuple[np.ndarray, np.ndarray]:\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(data) - seq_len):\n",
    "        X.append(data[i:i+seq_len])\n",
    "        if target_sequence:\n",
    "            y.append(data[(i+1):(i+1+seq_len)])\n",
    "        else:\n",
    "            y.append(data[i+seq_len])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (8872, 6), Test: (2219, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "\n",
    "X_train, X_test = train_test_split(X, test_size=0.2)\n",
    "\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "print(f'Train: {X_train.shape}, Test: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X, y_train: (8864, 8, 6) (8864, 8, 6)\n",
      "X, y_test: (2211, 8, 6) (2211, 8, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = create_sequence(X_train, target_sequence=True)\n",
    "X_test, y_test = create_sequence(X_test, target_sequence=True)\n",
    "\n",
    "print(f'X, y_train: {X_train.shape} {y_train.shape}')\n",
    "print(f'X, y_test: {X_test.shape} {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves the data and label at the given index.\n",
    "        \n",
    "        Args:\n",
    "            idx (int): The index of the sample to retrieve.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (data, label)\n",
    "        \"\"\"\n",
    "        sample = self.data[idx]\n",
    "        target = self.targets[idx]\n",
    "        return sample, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "X_train, X_test, y_train, y_test = torch.Tensor(X_train), torch.Tensor(X_test), torch.Tensor(y_train), torch.Tensor(y_test)\n",
    "X_train, X_test, y_train, y_test = X_train.to(device), X_test.to(device), y_train.to(device), y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "dataset_train = StockDataset(X_train, y_train)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataset_test = StockDataset(X_test, y_test)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_heads, num_layers=6, hidden_dim=64, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        #self.fc_in = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        # Define the Transformer model\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=hidden_dim,    # the dimension of input and output\n",
    "            nhead=num_heads,       # the number of attention heads\n",
    "            num_encoder_layers=num_layers,  # number of encoder layers\n",
    "            num_decoder_layers=num_layers,  # number of decoder layers\n",
    "            dim_feedforward=hidden_dim * 4,  # feedforward dimension inside the transformer\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Output layer (linear transformation from hidden_dim to output_dim)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        #output = self.fc_in(src)\n",
    "        output = self.transformer(src, tgt)\n",
    "        output = self.fc_out(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 8\n",
    "n_features = 6  # Number of financial indicators\n",
    "\n",
    "model = TransformerModel(input_dim=n_features, output_dim=n_features, num_heads=6, hidden_dim=n_features)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.5399732061456687\n",
      "Epoch: 2, Loss: 0.12883727711084086\n",
      "Epoch: 3, Loss: 0.0735212061621437\n",
      "Epoch: 4, Loss: 0.052798211964566785\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m dataloader_train:\n\u001b[1;32m     11\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 12\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[1;32m     14\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Programi/Python_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programi/Python_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[60], line 23\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[0;34m(self, src, tgt)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, src, tgt):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m#output = self.fc_in(src)\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_out(output)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/Programi/Python_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programi/Python_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Programi/Python_venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:278\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask, src_is_causal, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    270\u001b[0m     )\n\u001b[1;32m    272\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    273\u001b[0m     src,\n\u001b[1;32m    274\u001b[0m     mask\u001b[38;5;241m=\u001b[39msrc_mask,\n\u001b[1;32m    275\u001b[0m     src_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_key_padding_mask,\n\u001b[1;32m    276\u001b[0m     is_causal\u001b[38;5;241m=\u001b[39msrc_is_causal,\n\u001b[1;32m    277\u001b[0m )\n\u001b[0;32m--> 278\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/Programi/Python_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programi/Python_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Programi/Python_venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:602\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    599\u001b[0m tgt_is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(tgt_mask, tgt_is_causal, seq_len)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 602\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    614\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(output)\n",
      "File \u001b[0;32m~/Programi/Python_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programi/Python_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Programi/Python_venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:1091\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1086\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(\n\u001b[1;32m   1087\u001b[0m         x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal)\n\u001b[1;32m   1088\u001b[0m     )\n\u001b[1;32m   1089\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(\n\u001b[1;32m   1090\u001b[0m         x\n\u001b[0;32m-> 1091\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mha_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1094\u001b[0m     )\n\u001b[1;32m   1095\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Programi/Python_venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:1127\u001b[0m, in \u001b[0;36mTransformerDecoderLayer._mha_block\u001b[0;34m(self, x, mem, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_mha_block\u001b[39m(\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1121\u001b[0m     x: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1125\u001b[0m     is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1126\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1127\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultihead_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(x)\n",
      "File \u001b[0;32m~/Programi/Python_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programi/Python_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Programi/Python_venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:1368\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1343\u001b[0m         query,\n\u001b[1;32m   1344\u001b[0m         key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[1;32m   1366\u001b[0m     )\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1368\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1388\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/Programi/Python_venv/lib/python3.10/site-packages/torch/nn/functional.py:6097\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   6093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_separate_proj_weight:\n\u001b[1;32m   6094\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m   6095\u001b[0m         in_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   6096\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_separate_proj_weight is False but in_proj_weight is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 6097\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m \u001b[43m_in_projection_packed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6098\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6099\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m   6100\u001b[0m         q_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   6101\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_separate_proj_weight is True but q_proj_weight is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Programi/Python_venv/lib/python3.10/site-packages/torch/nn/functional.py:5525\u001b[0m, in \u001b[0;36m_in_projection_packed\u001b[0;34m(q, k, v, w, b)\u001b[0m\n\u001b[1;32m   5519\u001b[0m         kv_proj \u001b[38;5;241m=\u001b[39m linear(k, w_kv, b_kv)\n\u001b[1;32m   5520\u001b[0m         \u001b[38;5;66;03m# reshape to 2, E and not E, 2 is deliberate for better memory coalescing and keeping same order as chunk()\u001b[39;00m\n\u001b[1;32m   5521\u001b[0m         kv_proj \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   5522\u001b[0m             \u001b[43mkv_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5523\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5524\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m-> 5525\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5526\u001b[0m             \u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m   5527\u001b[0m         )\n\u001b[1;32m   5528\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (q_proj, kv_proj[\u001b[38;5;241m0\u001b[39m], kv_proj[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m   5529\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(100):\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for data, target in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data, target)\n",
    "        loss = criterion(output, target)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch: {epoch+1}, Loss: {epoch_loss / len(dataloader_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.020611751824617386\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    val_output = model(X_test, y_test)\n",
    "    val_loss = criterion(val_output, y_test)\n",
    "    print(f\"Validation Loss: {val_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (8, 6), (8, 6)\n"
     ]
    }
   ],
   "source": [
    "true_unscaled = scaler_X.inverse_transform(y_test[0].cpu())\n",
    "predicted_unscaled = scaler_X.inverse_transform(val_output[0].cpu())\n",
    "print(f'Shapes: {true_unscaled.shape}, {predicted_unscaled.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [i for i in range(len(true_unscaled))]\n",
    "plt.plot(x, true_unscaled[:, 0], color='blue')\n",
    "plt.plot(x,predicted_unscaled[:, 0], color='red')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
