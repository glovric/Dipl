{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # type: ignore\n",
    "import pandas as pd # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import yfinance as yf # type: ignore\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "data = yf.download('AAPL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-12-12</th>\n",
       "      <td>0.098834</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>469033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-15</th>\n",
       "      <td>0.093678</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.122210</td>\n",
       "      <td>175884800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-16</th>\n",
       "      <td>0.086802</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>105728000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-17</th>\n",
       "      <td>0.088951</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.116071</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>86441600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-18</th>\n",
       "      <td>0.091530</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.119420</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>73449600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price      Adj Close     Close      High       Low      Open     Volume\n",
       "Ticker          AAPL      AAPL      AAPL      AAPL      AAPL       AAPL\n",
       "Date                                                                   \n",
       "1980-12-12  0.098834  0.128348  0.128906  0.128348  0.128348  469033600\n",
       "1980-12-15  0.093678  0.121652  0.122210  0.121652  0.122210  175884800\n",
       "1980-12-16  0.086802  0.112723  0.113281  0.112723  0.113281  105728000\n",
       "1980-12-17  0.088951  0.115513  0.116071  0.115513  0.115513   86441600\n",
       "1980-12-18  0.091530  0.118862  0.119420  0.118862  0.118862   73449600"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11093, 6)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.to_numpy()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence(data: np.ndarray, seq_len: int = 8, target_sequence: bool = False) -> tuple[np.ndarray, np.ndarray]:\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(data) - seq_len):\n",
    "        X.append(data[i:i+seq_len])\n",
    "        if target_sequence:\n",
    "            y.append(data[(i+1):(i+1+seq_len)])\n",
    "        else:\n",
    "            y.append(data[i+seq_len])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (8874, 6), Test: (2219, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "\n",
    "X_train, X_test = train_test_split(X, test_size=0.2)\n",
    "\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "print(f'Train: {X_train.shape}, Test: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X, y_train: (8866, 8, 6) (8866, 6)\n",
      "X, y_test: (2211, 8, 6) (2211, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = create_sequence(X_train)\n",
    "X_test, y_test = create_sequence(X_test)\n",
    "\n",
    "print(f'X, y_train: {X_train.shape} {y_train.shape}')\n",
    "print(f'X, y_test: {X_test.shape} {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train, y_test: (8866, 1, 6), (2211, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "y_train, y_test = y_train.reshape(-1, 1, 6), y_test.reshape(-1, 1, 6)\n",
    "print(f'y_train, y_test: {y_train.shape}, {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves the data and label at the given index.\n",
    "        \n",
    "        Args:\n",
    "            idx (int): The index of the sample to retrieve.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (data, label)\n",
    "        \"\"\"\n",
    "        sample = self.data[idx]\n",
    "        target = self.targets[idx]\n",
    "        return sample, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "X_train, X_test, y_train, y_test = torch.Tensor(X_train), torch.Tensor(X_test), torch.Tensor(y_train), torch.Tensor(y_test)\n",
    "X_train, X_test, y_train, y_test = X_train.to(device), X_test.to(device), y_train.to(device), y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "dataset_train = StockDataset(X_train, y_train)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataset_test = StockDataset(X_test, y_test)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_heads, num_layers=6, dim_ff=2048, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        # Define the Transformer model\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=input_dim,    # the dimension of input and output\n",
    "            nhead=num_heads,       # the number of attention heads\n",
    "            num_encoder_layers=num_layers,  # number of encoder layers\n",
    "            num_decoder_layers=num_layers,  # number of decoder layers\n",
    "            dim_feedforward=dim_ff,  # feedforward dimension inside the transformer\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Output layer (linear transformation from hidden_dim to output_dim)\n",
    "        self.fc_out = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        output = self.transformer(src, tgt)\n",
    "        #output = output[:, -1, :] # For one output instead of sequence\n",
    "        output = self.fc_out(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 6  # Number of financial indicators\n",
    "\n",
    "model = TransformerModel(input_dim=n_features, output_dim=n_features, num_heads=6)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "For unbatched (2-D) `query`, expected `key` and `value` to be 2-D but found 3-D and 3-D tensors respectively",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Grgo\\Faks\\Dipl\\torch_transformer_test.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Grgo/Faks/Dipl/torch_transformer_test.ipynb#X55sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Grgo/Faks/Dipl/torch_transformer_test.ipynb#X55sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m target \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Grgo/Faks/Dipl/torch_transformer_test.ipynb#X55sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m output \u001b[39m=\u001b[39m model(data, target)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Grgo/Faks/Dipl/torch_transformer_test.ipynb#X55sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, target)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Grgo/Faks/Dipl/torch_transformer_test.ipynb#X55sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32md:\\Grgo\\Programs\\Python_venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Grgo\\Programs\\Python_venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "\u001b[1;32md:\\Grgo\\Faks\\Dipl\\torch_transformer_test.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Grgo/Faks/Dipl/torch_transformer_test.ipynb#X55sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, src, tgt):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Grgo/Faks/Dipl/torch_transformer_test.ipynb#X55sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(src, tgt)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Grgo/Faks/Dipl/torch_transformer_test.ipynb#X55sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     output \u001b[39m=\u001b[39m output[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :] \u001b[39m# For one output instead of sequence\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Grgo/Faks/Dipl/torch_transformer_test.ipynb#X55sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_out(output)\n",
      "File \u001b[1;32md:\\Grgo\\Programs\\Python_venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Grgo\\Programs\\Python_venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Grgo\\Programs\\Python_venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:278\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask, src_is_causal, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    269\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    270\u001b[0m     )\n\u001b[0;32m    272\u001b[0m memory \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(\n\u001b[0;32m    273\u001b[0m     src,\n\u001b[0;32m    274\u001b[0m     mask\u001b[39m=\u001b[39msrc_mask,\n\u001b[0;32m    275\u001b[0m     src_key_padding_mask\u001b[39m=\u001b[39msrc_key_padding_mask,\n\u001b[0;32m    276\u001b[0m     is_causal\u001b[39m=\u001b[39msrc_is_causal,\n\u001b[0;32m    277\u001b[0m )\n\u001b[1;32m--> 278\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[0;32m    279\u001b[0m     tgt,\n\u001b[0;32m    280\u001b[0m     memory,\n\u001b[0;32m    281\u001b[0m     tgt_mask\u001b[39m=\u001b[39;49mtgt_mask,\n\u001b[0;32m    282\u001b[0m     memory_mask\u001b[39m=\u001b[39;49mmemory_mask,\n\u001b[0;32m    283\u001b[0m     tgt_key_padding_mask\u001b[39m=\u001b[39;49mtgt_key_padding_mask,\n\u001b[0;32m    284\u001b[0m     memory_key_padding_mask\u001b[39m=\u001b[39;49mmemory_key_padding_mask,\n\u001b[0;32m    285\u001b[0m     tgt_is_causal\u001b[39m=\u001b[39;49mtgt_is_causal,\n\u001b[0;32m    286\u001b[0m     memory_is_causal\u001b[39m=\u001b[39;49mmemory_is_causal,\n\u001b[0;32m    287\u001b[0m )\n\u001b[0;32m    288\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32md:\\Grgo\\Programs\\Python_venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Grgo\\Programs\\Python_venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Grgo\\Programs\\Python_venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:602\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m    599\u001b[0m tgt_is_causal \u001b[39m=\u001b[39m _detect_is_causal_mask(tgt_mask, tgt_is_causal, seq_len)\n\u001b[0;32m    601\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m--> 602\u001b[0m     output \u001b[39m=\u001b[39m mod(\n\u001b[0;32m    603\u001b[0m         output,\n\u001b[0;32m    604\u001b[0m         memory,\n\u001b[0;32m    605\u001b[0m         tgt_mask\u001b[39m=\u001b[39;49mtgt_mask,\n\u001b[0;32m    606\u001b[0m         memory_mask\u001b[39m=\u001b[39;49mmemory_mask,\n\u001b[0;32m    607\u001b[0m         tgt_key_padding_mask\u001b[39m=\u001b[39;49mtgt_key_padding_mask,\n\u001b[0;32m    608\u001b[0m         memory_key_padding_mask\u001b[39m=\u001b[39;49mmemory_key_padding_mask,\n\u001b[0;32m    609\u001b[0m         tgt_is_causal\u001b[39m=\u001b[39;49mtgt_is_causal,\n\u001b[0;32m    610\u001b[0m         memory_is_causal\u001b[39m=\u001b[39;49mmemory_is_causal,\n\u001b[0;32m    611\u001b[0m     )\n\u001b[0;32m    613\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    614\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(output)\n",
      "File \u001b[1;32md:\\Grgo\\Programs\\Python_venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Grgo\\Programs\\Python_venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Grgo\\Programs\\Python_venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:1091\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1086\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(\n\u001b[0;32m   1087\u001b[0m         x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal)\n\u001b[0;32m   1088\u001b[0m     )\n\u001b[0;32m   1089\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(\n\u001b[0;32m   1090\u001b[0m         x\n\u001b[1;32m-> 1091\u001b[0m         \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mha_block(\n\u001b[0;32m   1092\u001b[0m             x, memory, memory_mask, memory_key_padding_mask, memory_is_causal\n\u001b[0;32m   1093\u001b[0m         )\n\u001b[0;32m   1094\u001b[0m     )\n\u001b[0;32m   1095\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm3(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(x))\n\u001b[0;32m   1097\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32md:\\Grgo\\Programs\\Python_venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:1127\u001b[0m, in \u001b[0;36mTransformerDecoderLayer._mha_block\u001b[1;34m(self, x, mem, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m   1119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_mha_block\u001b[39m(\n\u001b[0;32m   1120\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1121\u001b[0m     x: Tensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1125\u001b[0m     is_causal: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1126\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> 1127\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmultihead_attn(\n\u001b[0;32m   1128\u001b[0m         x,\n\u001b[0;32m   1129\u001b[0m         mem,\n\u001b[0;32m   1130\u001b[0m         mem,\n\u001b[0;32m   1131\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[0;32m   1132\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[0;32m   1133\u001b[0m         is_causal\u001b[39m=\u001b[39;49mis_causal,\n\u001b[0;32m   1134\u001b[0m         need_weights\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1135\u001b[0m     )[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1136\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout2(x)\n",
      "File \u001b[1;32md:\\Grgo\\Programs\\Python_venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Grgo\\Programs\\Python_venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Grgo\\Programs\\Python_venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1368\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1343\u001b[0m         query,\n\u001b[0;32m   1344\u001b[0m         key,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         is_causal\u001b[39m=\u001b[39mis_causal,\n\u001b[0;32m   1366\u001b[0m     )\n\u001b[0;32m   1367\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1368\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[0;32m   1369\u001b[0m         query,\n\u001b[0;32m   1370\u001b[0m         key,\n\u001b[0;32m   1371\u001b[0m         value,\n\u001b[0;32m   1372\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim,\n\u001b[0;32m   1373\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[0;32m   1374\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight,\n\u001b[0;32m   1375\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[0;32m   1376\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k,\n\u001b[0;32m   1377\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v,\n\u001b[0;32m   1378\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[0;32m   1379\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout,\n\u001b[0;32m   1380\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m   1381\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[0;32m   1382\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[0;32m   1383\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[0;32m   1384\u001b[0m         need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[0;32m   1385\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[0;32m   1386\u001b[0m         average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights,\n\u001b[0;32m   1387\u001b[0m         is_causal\u001b[39m=\u001b[39;49mis_causal,\n\u001b[0;32m   1388\u001b[0m     )\n\u001b[0;32m   1389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[0;32m   1390\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32md:\\Grgo\\Programs\\Python_venv\\Lib\\site-packages\\torch\\nn\\functional.py:6014\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   5983\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function(tens_ops):\n\u001b[0;32m   5984\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   5985\u001b[0m         multi_head_attention_forward,\n\u001b[0;32m   5986\u001b[0m         tens_ops,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6011\u001b[0m         average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n\u001b[0;32m   6012\u001b[0m     )\n\u001b[1;32m-> 6014\u001b[0m is_batched \u001b[39m=\u001b[39m _mha_shape_check(\n\u001b[0;32m   6015\u001b[0m     query, key, value, key_padding_mask, attn_mask, num_heads\n\u001b[0;32m   6016\u001b[0m )\n\u001b[0;32m   6018\u001b[0m \u001b[39m# For unbatched input, we unsqueeze at the expected batch-dim to pretend that the input\u001b[39;00m\n\u001b[0;32m   6019\u001b[0m \u001b[39m# is batched, run the computation and before returning squeeze the\u001b[39;00m\n\u001b[0;32m   6020\u001b[0m \u001b[39m# batch dimension so that the output doesn't carry this temporary batch dimension.\u001b[39;00m\n\u001b[0;32m   6021\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_batched:\n\u001b[0;32m   6022\u001b[0m     \u001b[39m# unsqueeze if the input is unbatched\u001b[39;00m\n",
      "File \u001b[1;32md:\\Grgo\\Programs\\Python_venv\\Lib\\site-packages\\torch\\nn\\functional.py:5803\u001b[0m, in \u001b[0;36m_mha_shape_check\u001b[1;34m(query, key, value, key_padding_mask, attn_mask, num_heads)\u001b[0m\n\u001b[0;32m   5800\u001b[0m \u001b[39melif\u001b[39;00m query\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m   5801\u001b[0m     \u001b[39m# Unbatched Inputs\u001b[39;00m\n\u001b[0;32m   5802\u001b[0m     is_batched \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 5803\u001b[0m     \u001b[39massert\u001b[39;00m key\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m, (\n\u001b[0;32m   5804\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFor unbatched (2-D) `query`, expected `key` and `value` to be 2-D\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   5805\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m but found \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m.\u001b[39mdim()\u001b[39m}\u001b[39;00m\u001b[39m-D and \u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m.\u001b[39mdim()\u001b[39m}\u001b[39;00m\u001b[39m-D tensors respectively\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   5806\u001b[0m     )\n\u001b[0;32m   5808\u001b[0m     \u001b[39mif\u001b[39;00m key_padding_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5809\u001b[0m         \u001b[39massert\u001b[39;00m key_padding_mask\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m, (\n\u001b[0;32m   5810\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFor unbatched (2-D) `query`, expected `key_padding_mask` to be `None` or 1-D\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   5811\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m but found \u001b[39m\u001b[39m{\u001b[39;00mkey_padding_mask\u001b[39m.\u001b[39mdim()\u001b[39m}\u001b[39;00m\u001b[39m-D tensor instead\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   5812\u001b[0m         )\n",
      "\u001b[1;31mAssertionError\u001b[0m: For unbatched (2-D) `query`, expected `key` and `value` to be 2-D but found 3-D and 3-D tensors respectively"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(100):\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for data, target in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data, target)\n",
    "        loss = criterion(output, target)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch: {epoch+1}, Loss: {epoch_loss / len(dataloader_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.05306186527013779\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    val_output = model(X_test, y_test)\n",
    "    val_loss = criterion(val_output, y_test)\n",
    "    print(f\"Validation Loss: {val_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (20, 6), (20, 6)\n"
     ]
    }
   ],
   "source": [
    "true_unscaled = scaler_X.inverse_transform(y_test.reshape(-1, 6).cpu())[:20]\n",
    "predicted_unscaled = scaler_X.inverse_transform(val_output.reshape(-1, 6).cpu())[:20]\n",
    "print(f'Shapes: {true_unscaled.shape}, {predicted_unscaled.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [i for i in range(len(true_unscaled))]\n",
    "plt.plot(x, true_unscaled[:, 0], color='blue')\n",
    "plt.plot(x,predicted_unscaled[:, 0], color='red')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
